# -*- coding: utf-8 -*-
"""Spectromorph_Assignment1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LqYfi0LqN29dDQ2Dz8YK5br86e2oOykU
"""

from google.colab import drive
drive.mount('/content/drive')
path = '/content/drive/My Drive/Spectromorph_Assignment_1/dataset'



import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import ImageFolder
from PIL import Image

# Device Config
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class RGBADataset(ImageFolder):
    def __init__(self, root, transform=None):
        super().__init__(root, transform=transform)

    def __getitem__(self, index):
        path, target = self.samples[index]
        img = Image.open(path).convert("RGBA")  # Ensure RGBA input

        # Convert white background to RGBA too
        background = Image.new("RGBA", img.size, (255, 255, 255, 255))
        img = Image.alpha_composite(background, img).convert("RGB")  

        if self.transform is not None:
            img = self.transform(img)

        return img, target

from torchvision import transforms

transform_train = transforms.Compose([
    transforms.Resize((140, 140)),
    transforms.RandomCrop((128, 128)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomRotation(degrees=15),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),
    transforms.ToTensor(),
    # Optional: normalize if needed
    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

dataset = RGBADataset(root=path, transform=transform_train)

from torch.utils.data import random_split, DataLoader
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

import matplotlib.pyplot as plt

def show_tensor_image(tensor_img, title=""):
    img = tensor_img.permute(1, 2, 0).numpy()
    plt.imshow(img)
    plt.title(title)
    plt.axis("off")
    plt.show()

# Visual check
img_tensor, label = train_dataset[0]
show_tensor_image(img_tensor, f"Class: {label}")

# Hyperparams
num_classes = 18
learning_rate = 0.001
num_epochs = 100

class SimpleCNN(nn.Module):
  def __init__(self):
    super(SimpleCNN,self).__init__()
    self.conv1 = nn.Conv2d(3, 16, 3, padding=1)     # nn.Conv2d(in_channels,out_channels,Kernal_Size)
    self.pool = nn.MaxPool2d(2, 2)                  # Output = [Input_Size + 2*Padding - Kernal_Size]/Stride + 1
    self.conv2 = nn.Conv2d(16, 32, 3, padding=1)    # Default_stride =1
    self.fc1 = nn.Linear(32 * 32 * 32, 128)
    self.drop = nn.Dropout(0.2)
    self.fc2 = nn.Linear(128, num_classes)
    self.relu = nn.ReLU()

  def forward(self, x):
    out1 = self.pool(self.relu(self.conv1(x)))
    out2 = self.pool(self.relu(self.conv2(out1)))
    out3 = out2.view(-1, 32 * 32 * 32)
    out4 = self.relu(self.fc1(out3))
    out5 = self.fc2(self.drop(out4))
    return out5

model = SimpleCNN()
model = model.to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

model.train()
for epoch in range(num_epochs):
    running_loss = 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        #print(1)

        running_loss += loss.item()

    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}')

model.eval()
correct = 0
total = 0

with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy: {100 * correct / total:.2f}%')